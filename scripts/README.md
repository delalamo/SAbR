# SAbR Scripts

_DDA: this README and all the scripts in this directory are entirely vibe coded. I did not read them and do not endorse their contents._

This directory contains benchmarking scripts for the SAbR (Structure-based Antibody Renumbering) project.

### Why Two Stages?

1. **Embedding generation is expensive**: MPNN embeddings require GPU/CPU computation and take time to generate. Saving them to NPZ files allows for:
   - Reusing embeddings across multiple benchmarks
   - Testing different numbering schemes without regenerating embeddings
   - Sharing precomputed embeddings with collaborators

2. **Benchmarking is fast**: Once embeddings are saved, comparing renumbering results is quick and can be run with different parameters (chain types, numbering schemes) without regeneration.

---

## sabdab_to_csv.py

Generate a CSV file from SAbDab summary TSV for batch embedding creation.

### Description

This script processes the **SAbDab summary file** (downloadable from [SAbDab](http://opig.stats.ox.ac.uk/webapps/newsabdab/sabdab/summary/all/)) and creates a CSV file specifying which PDB files and chains to process for embedding generation.

The SAbDab (Structural Antibody Database) summary file contains comprehensive information about all antibody structures in the PDB, including chain identifiers for heavy and light chains, resolution, experimental method, and more.

**What it does:**

1. Reads the SAbDab summary TSV file
2. Filters structures based on chain type, resolution, method, etc.
3. Extracts PDB IDs and chain identifiers
4. Outputs a CSV file with `pdb_id` and `chain` columns for use with `create_embeddings.py`

### Usage

```bash
python scripts/sabdab_to_csv.py \
    --tsv <sabdab-summary-file.tsv> \
    --output <output.csv> \
    [OPTIONS]
```

### Arguments

#### Required Arguments

- `--tsv PATH`
  Path to SAbDab summary TSV file (e.g., `sabdab_summary_all.tsv`)
  Download from: http://opig.stats.ox.ac.uk/webapps/newsabdab/sabdab/summary/all/

- `--output PATH`
  Output CSV file path

#### Optional Arguments

- `--chain-type {heavy,light,both,all}`
  Which chains to include (default: `both`)
  - `heavy`: Heavy chains only (H chains)
  - `light`: Light chains only (L chains)
  - `both`: Both heavy and light chains
  - `all`: All antibody chains including nanobodies

- `--max-entries N`
  Maximum number of entries to include (0 = all, default: `0`)

- `--filter-resolution FLOAT`
  Only include structures with resolution ≤ this value in Å (0 = no filter, default: `0`)

- `--filter-method {X-RAY DIFFRACTION,ELECTRON MICROSCOPY,any}`
  Filter by experimental method (default: `any`)

- `--no-scfv`
  Exclude scFv (single-chain variable fragment) structures

- `--verbose`
  Show detailed output for each entry added

- `-h, --help`
  Show help message and exit

### Examples

```bash
# Generate CSV for all heavy chains with resolution ≤ 2.5 Å
python scripts/sabdab_to_csv.py \
    --tsv ~/data/sabdab_summary_all.tsv \
    --output ~/data/high_res_heavy.csv \
    --chain-type heavy \
    --filter-resolution 2.5

# Generate CSV for X-ray structures only (no scFv)
python scripts/sabdab_to_csv.py \
    --tsv ~/data/sabdab_summary_all.tsv \
    --output ~/data/xray_only.csv \
    --filter-method "X-RAY DIFFRACTION" \
    --no-scfv

# Generate CSV for first 100 antibody structures (any chain type)
python scripts/sabdab_to_csv.py \
    --tsv ~/data/sabdab_summary_all.tsv \
    --output ~/data/sample_100.csv \
    --max-entries 100 \
    --verbose
```

### Output Format

The output CSV file has two columns:

```csv
pdb_id,chain
9pix,H
9pkc,H
8yub,A
8yub,D
...
```

This CSV can be used directly with `create_embeddings.py --csv` option.

---

## create_embeddings.py

Generate MPNN embeddings from PDB files and save them as NPZ files.

### Description

This script processes PDB structures to create MPNN (Message Passing Neural Network) embeddings, which capture structural information about each residue. The embeddings are saved in NumPy's compressed NPZ format for downstream use.

**The script supports two modes:**

1. **Directory mode**: Process all PDB files in a directory with a single chain identifier
2. **CSV mode**: Process specific PDB/chain combinations from a CSV file (generated by `sabdab_to_csv.py`)

**What it does:**

1. Reads PDB files (from directory or CSV list)
2. Extracts the specified chain from each structure
3. Generates MPNN embeddings (64-dimensional vectors per residue)
4. Saves embeddings, residue identifiers, standard deviations, and sequence to NPZ files

### Usage

```bash
# Directory mode
python scripts/create_embeddings.py \
    --pdb-dir <directory-with-pdb-files> \
    --output-dir <directory-for-npz-files> \
    [OPTIONS]

# CSV mode
python scripts/create_embeddings.py \
    --pdb-dir <directory-with-pdb-files> \
    --output-dir <directory-for-npz-files> \
    --csv <input.csv> \
    [OPTIONS]
```

### Arguments

#### Required Arguments

- `--pdb-dir PATH`
  Directory containing PDB files to process

- `--output-dir PATH`
  Directory where NPZ embedding files will be saved (created if doesn't exist)

#### Mode Selection

- `--csv PATH`
  CSV file with `pdb_id` and `chain` columns (enables CSV mode)
  If provided, overrides `--chain` and `--pattern` options

#### Directory Mode Arguments (ignored in CSV mode)

- `--chain CHAIN_ID`
  Chain identifier to embed (default: `A`)

- `--pattern GLOB`
  Glob pattern for matching PDB files (default: `*.pdb`)
  Examples: `*.pdb`, `antibody_*.pdb`, `1abc.pdb`

#### Common Arguments

- `--max-residues N`
  Maximum number of residues to process (0 = no limit, default: `0`)

- `--skip-existing`
  Skip processing if the output NPZ file already exists

- `--verbose`
  Show detailed output for each file (embedding shape, sequence length, etc.)

- `-h, --help`
  Show help message and exit

### Examples

```bash
# Directory mode: process all PDB files in a directory with chain A
python scripts/create_embeddings.py \
    --pdb-dir ~/data/antibodies \
    --output-dir ~/data/embeddings \
    --chain A

# Directory mode: process specific chain with detailed output
python scripts/create_embeddings.py \
    --pdb-dir ~/data/antibodies \
    --output-dir ~/data/embeddings \
    --chain H \
    --verbose

# CSV mode: process PDB/chain pairs from SAbDab CSV
python scripts/create_embeddings.py \
    --pdb-dir ~/data/pdb_files \
    --output-dir ~/data/embeddings \
    --csv ~/data/antibodies.csv

# CSV mode with skip-existing (resume interrupted processing)
python scripts/create_embeddings.py \
    --pdb-dir ~/data/pdb_files \
    --output-dir ~/data/embeddings \
    --csv ~/data/antibodies.csv \
    --skip-existing
```

### Output

**Directory mode**: Each PDB file generates one NPZ file with the same base name:

- Input: `antibody_1.pdb` → Output: `antibody_1.npz`

**CSV mode**: Each PDB/chain combination generates one NPZ file:

- Input: `1abc.pdb` chain `H` → Output: `1abc_H.npz`
- Input: `1abc.pdb` chain `L` → Output: `1abc_L.npz`

NPZ files contain:

- `embeddings`: MPNN embedding vectors (N×64 array)
- `idxs`: Residue identifiers (list of strings)
- `stdev`: Standard deviations (N×64 array)
- `sequence`: Amino acid sequence (string)
- `name`: Embedding name (string, usually "INPUT_PDB")

### Example Output

```
INFO:__main__:CSV mode: processing PDB/chain pairs from CSV file
INFO:__main__:Output directory: /data/embeddings
INFO:__main__:Found 150 entries from CSV
INFO:__main__:Processing 9pix.pdb (chain H)...
INFO:__main__:  → 9pix_H.npz (118 residues)
INFO:__main__:Processing 9pkc.pdb (chain H)...
INFO:__main__:  → 9pkc_H.npz (121 residues)
...
INFO:__main__:======================================================================
INFO:__main__:SUMMARY
INFO:__main__:======================================================================
INFO:__main__:Total tasks: 150
INFO:__main__:Successfully processed: 147
INFO:__main__:Skipped (already exist): 0
INFO:__main__:Failed: 3
INFO:__main__:Output directory: /data/embeddings
```

---

## benchmark.py

Benchmark renumbering accuracy from precomputed NPZ embedding files.

### Description

This script evaluates the accuracy of SAbR's renumbering pipeline by comparing renumbering results against original PDB numbering. It:

1. Loads precomputed MPNN embeddings from NPZ files (created by `create_embeddings.py`)
2. Runs them through the SAbR renumbering workflow:
   - **SoftAlign**: Aligns embeddings against species reference templates
   - **ANARCI**: Assigns numbering according to the specified scheme (default: IMGT)
3. Compares the assigned numbering to the original PDB numbering
4. Reports accuracy statistics (match rate, deviations per file, etc.)

**Key features:**

- Normalizes insertion codes to avoid false positives (treats empty strings and spaces as equivalent)
- Provides detailed per-file statistics with `--verbose` flag
- Supports different chain types (heavy, light, auto-detect)
- Configurable numbering schemes (IMGT, Chothia, Kabat, etc.)

### Usage

```bash
python scripts/benchmark.py \
    --npz-dir <path-to-npz-files> \
    --pdb-dir <path-to-original-pdbs> \
    [OPTIONS]
```

### Arguments

#### Required Arguments

- `--npz-dir PATH`
  Directory containing NPZ embedding files (.npz). These should be precomputed embeddings created by `create_embeddings.py`.

- `--pdb-dir PATH`
  Directory containing the original PDB files (.pdb). The script matches NPZ files to PDB files by base name (e.g., `protein.npz` → `protein.pdb`).

#### Optional Arguments

- `--chain CHAIN_ID`
  Chain identifier to use from PDB files (default: `A`)

- `--chain-type {heavy,light,auto}`
  Chain type filter for SoftAlign alignment (default: `heavy`)
  - `heavy`: Filter to heavy chain references only
  - `light`: Filter to light chain references only
  - `auto`: Use all reference templates (auto-detect)

- `--scheme SCHEME`
  ANARCI numbering scheme (default: `imgt`)
  Common options: `imgt`, `chothia`, `kabat`, `aho`, `martin`

- `--verbose`
  Show detailed per-file output including individual deviations

- `-h, --help`
  Show help message and exit

### Examples

```bash
# Basic usage with default settings (IMGT scheme, heavy chains)
python scripts/benchmark.py \
    --npz-dir ~/data/embeddings \
    --pdb-dir ~/data/antibodies

# Detailed output with Chothia numbering
python scripts/benchmark.py \
    --npz-dir ~/data/embeddings \
    --pdb-dir ~/data/antibodies \
    --scheme chothia \
    --verbose

# Benchmark light chains with chain H
python scripts/benchmark.py \
    --npz-dir ~/data/embeddings \
    --pdb-dir ~/data/antibodies \
    --chain H \
    --chain-type light
```

### Output

The script outputs:

1. **Per-file processing** (with `--verbose`):
   - Number of residues compared
   - Number of matches and deviations
   - Match rate percentage
   - Details of first 5 deviations

2. **Summary statistics**:
   - Total files processed and failed
   - Total residues compared across all files
   - Total deviations across all files
   - Overall match rate
   - Per-file deviation counts (sorted by deviation count)

### Example Output

```
INFO:__main__:Found 36 NPZ files to process

INFO:__main__:======================================================================
INFO:__main__:SUMMARY
INFO:__main__:======================================================================
INFO:__main__:Files processed: 36
INFO:__main__:Files failed: 0
INFO:__main__:Total residues compared: 4451
INFO:__main__:Total deviations: 404
INFO:__main__:Overall match rate: 90.9%

INFO:__main__:Per-file deviation counts:
  22_29_renumbered.npz            123 deviations (4.7% match)
  25_6_renumbered.npz              19 deviations (85.7% match)
  2_0_renumbered.npz               19 deviations (82.2% match)
  ...
  12_40_renumbered.npz              0 deviations (100.0% match)
  4_26_renumbered.npz               0 deviations (100.0% match)

INFO:__main__:FINAL RESULT: 404 total deviations across all files
```

---

## Complete Pipeline Examples

### Example 1: Simple Directory-Based Pipeline

Process a directory of PDB files with a single chain:

```bash
# Stage 1: Create NPZ embeddings from PDB files
python scripts/create_embeddings.py \
    --pdb-dir ~/data/test_antibodies \
    --output-dir ~/data/test_embeddings \
    --chain A \
    --verbose

# Stage 2: Benchmark renumbering accuracy
python scripts/benchmark.py \
    --npz-dir ~/data/test_embeddings \
    --pdb-dir ~/data/test_antibodies \
    --chain A \
    --chain-type heavy \
    --scheme imgt \
    --verbose
```

### Example 2: SAbDab-Based Pipeline (Recommended for Large-Scale)

Process antibody structures from SAbDab with specific filtering:

```bash
# Step 0: Download SAbDab summary file
# Visit: http://opig.stats.ox.ac.uk/webapps/newsabdab/sabdab/summary/all/
# Download sabdab_summary_all.tsv

# Step 1: Generate CSV from SAbDab with filters
python scripts/sabdab_to_csv.py \
    --tsv ~/data/sabdab_summary_all.tsv \
    --output ~/data/high_res_antibodies.csv \
    --chain-type both \
    --filter-resolution 2.5 \
    --filter-method "X-RAY DIFFRACTION" \
    --no-scfv

# Step 2: Create NPZ embeddings from CSV
python scripts/create_embeddings.py \
    --pdb-dir ~/data/pdb_files \
    --output-dir ~/data/embeddings \
    --csv ~/data/high_res_antibodies.csv \
    --skip-existing \
    --verbose

# Step 3: Benchmark renumbering accuracy
python scripts/benchmark.py \
    --npz-dir ~/data/embeddings \
    --pdb-dir ~/data/pdb_files \
    --chain-type heavy \
    --scheme imgt \
    --verbose
```

### Expected Workflow

**Directory-based workflow:**

1. **Prepare PDB files**: Collect antibody structures you want to test
2. **Generate embeddings**: Run `create_embeddings.py` once to create NPZ files
3. **Benchmark renumbering**: Run `benchmark.py` multiple times with different parameters

**SAbDab-based workflow:**

1. **Download SAbDab summary**: Get the latest antibody structure metadata
2. **Filter and generate CSV**: Use `sabdab_to_csv.py` to select structures
3. **Generate embeddings**: Run `create_embeddings.py --csv` to create NPZ files
4. **Benchmark renumbering**: Run `benchmark.py` to evaluate accuracy

**Benefits of CSV mode:**

- Process specific chains from multi-chain PDB files
- Filter structures by resolution, method, or other criteria
- Handle large-scale datasets from SAbDab efficiently
- Resume interrupted processing with `--skip-existing`

**Multiple experiments:**
Run `benchmark.py` multiple times to test:

- Different numbering schemes (IMGT, Chothia, Kabat)
- Different chain type filters (heavy, light, auto)
- Compare results across experiments

---

## Technical Notes

### NPZ File Format

NPZ files created by `create_embeddings.py` contain:

- `embeddings`: MPNN embedding vectors (N×64 array)
- `idxs`: Residue identifiers (list of strings like "0_1", "1_2", ...)
- `stdev`: Standard deviations for embeddings (N×64 array)
- `sequence`: Amino acid sequence (string)
- `name`: Embedding name (string, typically "INPUT_PDB")

### Insertion Code Normalization

The benchmarking script normalizes insertion codes by stripping whitespace and treating empty strings as equivalent to single spaces. This prevents false positives from formatting differences:

- `(42, '')` is treated as equivalent to `(42, ' ')`
- `(42, 'A')` is NOT equivalent to `(42, '')` (true deviation)

### File Matching

Both scripts match PDB and NPZ files by base name (file stem):

- `antibody_heavy.pdb` ↔ `antibody_heavy.npz` ✓
- `1abc_H.pdb` ↔ `1abc_H.npz` ✓
- `test.pdb` ↔ `test_output.npz` ✗ (won't match)

### Chain Type Filtering

The `--chain-type` parameter in `benchmark.py` controls which reference templates are used during SoftAlign:

- `heavy`: Uses only heavy chain templates (3 human references)
- `light`: Uses only light chain templates (4 human references)
- `auto`: Uses all templates and auto-detects the best match (7 references total)

### Requirements

Both scripts require:

- `sabr` (this package)
- `ANARCI` (must be in `PYTHONPATH`)
- `BioPython`
- `numpy`
- `JAX` and `Haiku` (for MPNN embeddings)

### Environment Setup

```bash
# Activate conda environment
conda activate sabr_env

# Set JAX platform (for Mac M1/M2)
export JAX_PLATFORMS=cpu

# Set PYTHONPATH to include ANARCI
export PYTHONPATH=/path/to/SAbR/src:/path/to/ANARCI/src:$PYTHONPATH

# Run scripts
python scripts/create_embeddings.py ...
python scripts/benchmark.py ...
```

### Exit Codes

Both scripts use standard exit codes:

- `0`: Success (all files processed without errors)
- `1`: Failure (one or more files failed, or required directories not found)
